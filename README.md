# 一、项目目标
搭建一个基于Flask和通义千问qwen-omni-turbo模型API的对话机器人。

# 二、功能说明
## 2.1 主要功能
- 机器人角色设定：你的名字是赵敏敏，一个活泼可爱的女孩。请用活泼可爱的语气回答问题。保持回答简洁。
- 沟通渠道：你有2个沟通渠道，微信和电话。
- 微信沟通界面：类似于微信的对话框聊天界面，可以输入文字，发送语音、图片，赵敏敏也可以回复文字和语音。
- 电话沟通界面：类似于电话的语音对话界面，双工交互，可以实现语音对话。

# 三、项目落地

## 3.1 项目计划（RoadMap）
- ✅ Step1.搭建一个输入文本、输出文本的对话项目，实现基本的对话功能，不需要UI界面；
- ✅ Step2.实现微信沟通界面，类似于微信的对话框聊天界面，可以输入文字，赵敏敏也可以回复文字；
- ✅ Step3.迭代微信沟通界面，类似于微信的对话框聊天界面，可以输入文字，赵敏敏也可以回复文字或者选择语音，她的策略可以是短回复用文字，长回复用语音。
- Step4.迭代微信沟通界面，类似于微信的对话框聊天界面，可以输入文字、图片，赵敏敏也可以回复文字或者选择语音，她的策略可以是短回复用文字，长回复用语音。
- Step5.迭代微信沟通界面，类似于微信的对话框聊天界面，可以输入文字、图片、语音，赵敏敏也可以回复文字或者选择语音，她的策略可以是短回复用文字，长回复用语音。
- Step6.搭建类似于电话的语音对话界面，双工交互，可以实现语音对话。

## 3.2 已实现功能
- ✅ 完成基础文本对话功能（Step1）
  - 实现Flask后端服务框架
  - 使用OpenAI兼容模式集成通义千问qwen-omni-turbo API
  - 支持角色设定和个性化回复
- ✅ 实现微信风格聊天界面（Step2）
  - 类微信界面设计
  - 支持文本输入和显示
  - 区分用户和机器人消息样式
  - 支持回车快捷发送
- ✅ Step3.微信语音交互基础框架
  - 实现文字转语音合成（使用Cherry库）
  - 智能回复策略（<300字文字回复，≥300字自动转语音）
  - 语音消息播放控件集成
- ✅ Step4.多模态图片处理
  - 支持图片上传和预览
  - 图片描述生成功能
  - 多模态问答能力

## 3.3 尚未完全实现或需要优化的功能
- ⚠️ 电话语音双工交互（Step6）
- ⚠️ 性能优化
  - 流式响应优化
  - 错误处理与异常反馈机制
  - 大规模并发支持

## 3.4 技术栈
- 前端：HTML, CSS, JavaScript
- 后端：Python, Flask
- API：通义千问qwen-omni-turbo（使用OpenAI兼容模式）
- 音频处理：numpy, soundfile
- 语音合成：Cherry==0.8.0
- 图片处理：Pillow==10.3.0
- 异步支持：gevent==24.2.1
- 虚拟环境：venv

# 四、安装说明
## 环境要求
- Python 3.8+ 
- Node.js 14+（前端构建）

## 快速开始
```bash
# 克隆仓库
git clone https://github.com/rogerzhang666/ZMM_Ommi.git

# 安装依赖
cd ZMM_Ommi
python -m venv venv
venv\Scripts\activate
pip install -r requirements.txt

# 新增语音依赖安装
pip install cherry-python numpy soundfile
# 图片处理依赖
pip install Pillow

# 配置环境变量
在项目根目录创建.env文件，内容参考.env.example

# 启动服务
python main.py
```

## 项目结构
```
ZMM_Ommi/
├── app/                     # 应用代码目录
│   ├── __init__.py          # 应用初始化，包含工厂函数create_app
│   ├── routes.py            # API路由定义
│   ├── services/            # 服务层目录
│   │   ├── __init__.py      # 服务层初始化
│   │   └── chat_service.py  # 聊天服务实现，包含与API交互逻辑
│   ├── static/              # 静态资源目录
│   │   ├── css/             # 样式文件
│   │   ├── js/              # JavaScript脚本
│   │   ├── img/             # 图片资源
│   │   └── audio/           # 音频文件（语音合成结果）
│   └── templates/           # HTML模板
│       └── chat.html        # 聊天界面模板
│
├── config/                  # 配置目录
│   ├── __init__.py          # 中央配置模块，提供全局配置单例
│   └── settings.py          # 环境相关配置
│
├── reference/               # 参考文件目录
├── venv/                    # 虚拟环境
├── .env                     # 环境变量文件（不提交到版本控制）
├── .env.example             # 环境变量示例
├── .gitignore               # Git忽略文件
├── app.py                   # Flask应用入口
├── config.json              # 聊天机器人配置（角色设定等）
├── main.py                  # 应用启动脚本
├── README.md                # 项目说明文档
└── requirements.txt         # 依赖列表
```

## 核心文件说明

### 入口文件
- **main.py**: 应用启动脚本，负责初始化环境变量，创建应用实例，配置服务器参数
- **app.py**: Flask应用主文件，定义API路由，连接前端请求和后端服务

### 配置文件
- **config/__init__.py**: 中央配置模块，提供全局配置单例，统一管理系统配置
- **config.json**: 聊天机器人角色设定、语音阈值等配置
- **.env**: 环境变量配置，包含API密钥等敏感信息（本地开发使用）

### 服务层
- **app/services/chat_service.py**: 核心业务逻辑实现，处理与大模型API的交互，包含:
  - 文本对话处理
  - 语音合成逻辑
  - 多模态输入处理
  - 响应格式转换

### 前端界面
- **app/templates/chat.html**: 微信风格聊天界面模板
- **app/static/js/**: 前端交互脚本
  - 消息发送与接收
  - 语音播放控件
  - 图片上传处理

## 数据流向
1. 用户在前端输入消息/图片
2. 请求发送到 `/api/chat` 路由
3. 路由调用服务层 `chat_with_qianwen` 方法
4. 服务层与通义千问API交互
5. 根据响应长度判断是否需要语音
6. 返回文本/语音结果到前端
7. 前端展示文本并按需播放语音

## 开发者指南
- 添加新功能时，应遵循服务层与控制层分离的原则
- 业务逻辑应放在服务层实现，控制层只负责路由和请求处理
- 配置项统一在 `config/__init__.py` 中管理
- 敏感信息（API密钥等）统一使用环境变量管理
